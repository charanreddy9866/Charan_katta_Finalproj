{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e915e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.11/site-packages (1.23.5)\n",
      "Requirement already satisfied: pandas in ./anaconda3/lib/python3.11/site-packages (1.5.3)\n",
      "Requirement already satisfied: matplotlib in ./anaconda3/lib/python3.11/site-packages (3.7.1)\n",
      "Requirement already satisfied: seaborn in ./anaconda3/lib/python3.11/site-packages (0.12.2)\n",
      "Requirement already satisfied: scikit-learn in ./anaconda3/lib/python3.11/site-packages (1.3.0)\n",
      "Requirement already satisfied: tensorflow in ./anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in ./anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./anaconda3/lib/python3.11/site-packages (from pandas) (2022.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting jax>=0.3.15 (from tensorflow)\n",
      "  Obtaining dependency information for jax>=0.3.15 from https://files.pythonhosted.org/packages/dc/d9/f387d9dfb2cf00f814b24e0f8bf6f4c68ae01870994dc436993fadd73563/jax-0.4.26-py3-none-any.whl.metadata\n",
      "  Downloading jax-0.4.26-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/db/ed/1df62b44db2583375f6a8a5e2ca5432bbdc3edb477942b9b7c848c720055/libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (1.48.2)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.12.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in ./anaconda3/lib/python3.11/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./anaconda3/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Collecting ml-dtypes>=0.2.0 (from jax>=0.3.15->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes>=0.2.0 from https://files.pythonhosted.org/packages/42/6b/b2fa3e2386c2b7dde43f12b83c67f6e583039141dfbb58e5c8fd365a5a7d/ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata\n",
      "  Downloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./anaconda3/lib/python3.11/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: urllib3<2.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./anaconda3/lib/python3.11/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./anaconda3/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./anaconda3/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./anaconda3/lib/python3.11/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
      "Downloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_11_0_arm64.whl (26.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.0-cp311-cp311-macosx_10_9_universal2.whl (390 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m390.9/390.9 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: libclang, ml-dtypes, jax\n",
      "Successfully installed jax-0.4.26 libclang-18.1.1 ml-dtypes-0.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy pandas matplotlib seaborn scikit-learn tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e82798",
   "metadata": {},
   "source": [
    "# Importing the packages and libraries that are required for the project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "3a8d5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning algorithms\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Deep learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, GRU, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b94e25",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "cd68fddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"\n",
      "count                                               41188                                                                                                                                                                          \n",
      "unique                                              41176                                                                                                                                                                          \n",
      "top     27;\"technician\";\"single\";\"professional.course\"...                                                                                                                                                                          \n",
      "freq                                                    2                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/charanreddykatta/Downloads/bank+marketing/bank-additional/bank-additional-full.csv')\n",
    "\n",
    "\n",
    "# Display descriptive statistics\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "f96355fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]: df.info()\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 1 columns):\n",
      " #   Column                                                                                                                                                                                                                        Non-Null Count  Dtype \n",
      "---  ------                                                                                                                                                                                                                        --------------  ----- \n",
      " 0   age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"  41188 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 321.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# [4]: Information about the dataset\n",
    "print(\"[4]: df.info()\")\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "5772e8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]: df.head()\n",
      "  age;\"job\";\"marital\";\"education\";\"default\";\"housing\";\"loan\";\"contact\";\"month\";\"day_of_week\";\"duration\";\"campaign\";\"pdays\";\"previous\";\"poutcome\";\"emp.var.rate\";\"cons.price.idx\";\"cons.conf.idx\";\"euribor3m\";\"nr.employed\";\"y\"\n",
      "0  56;\"housemaid\";\"married\";\"basic.4y\";\"no\";\"no\";...                                                                                                                                                                          \n",
      "1  57;\"services\";\"married\";\"high.school\";\"unknown...                                                                                                                                                                          \n",
      "2  37;\"services\";\"married\";\"high.school\";\"no\";\"ye...                                                                                                                                                                          \n",
      "3  40;\"admin.\";\"married\";\"basic.6y\";\"no\";\"no\";\"no...                                                                                                                                                                          \n",
      "4  56;\"services\";\"married\";\"high.school\";\"no\";\"no...                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    " #Display the first few rows after preprocessing\n",
    "print(\"[6]: df.head()\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "3f489a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       age          job  marital            education  default housing loan  \\\n",
      "0       56    housemaid  married             basic.4y       no      no   no   \n",
      "1       57     services  married          high.school  unknown      no   no   \n",
      "2       37     services  married          high.school       no     yes   no   \n",
      "3       40       admin.  married             basic.6y       no      no   no   \n",
      "4       56     services  married          high.school       no      no  yes   \n",
      "...    ...          ...      ...                  ...      ...     ...  ...   \n",
      "41183   73      retired  married  professional.course       no     yes   no   \n",
      "41184   46  blue-collar  married  professional.course       no      no   no   \n",
      "41185   56      retired  married    university.degree       no     yes   no   \n",
      "41186   44   technician  married  professional.course       no      no   no   \n",
      "41187   74      retired  married  professional.course       no     yes   no   \n",
      "\n",
      "         contact month day_of_week  ...  campaign  pdays  previous  \\\n",
      "0      telephone   may         mon  ...         1    999         0   \n",
      "1      telephone   may         mon  ...         1    999         0   \n",
      "2      telephone   may         mon  ...         1    999         0   \n",
      "3      telephone   may         mon  ...         1    999         0   \n",
      "4      telephone   may         mon  ...         1    999         0   \n",
      "...          ...   ...         ...  ...       ...    ...       ...   \n",
      "41183   cellular   nov         fri  ...         1    999         0   \n",
      "41184   cellular   nov         fri  ...         1    999         0   \n",
      "41185   cellular   nov         fri  ...         2    999         0   \n",
      "41186   cellular   nov         fri  ...         1    999         0   \n",
      "41187   cellular   nov         fri  ...         3    999         1   \n",
      "\n",
      "          poutcome emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  \\\n",
      "0      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "1      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "2      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "3      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "4      nonexistent          1.1          93.994          -36.4      4.857   \n",
      "...            ...          ...             ...            ...        ...   \n",
      "41183  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "41184  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "41185  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "41186  nonexistent         -1.1          94.767          -50.8      1.028   \n",
      "41187      failure         -1.1          94.767          -50.8      1.028   \n",
      "\n",
      "       nr.employed    y  \n",
      "0           5191.0   no  \n",
      "1           5191.0   no  \n",
      "2           5191.0   no  \n",
      "3           5191.0   no  \n",
      "4           5191.0   no  \n",
      "...            ...  ...  \n",
      "41183       4963.6  yes  \n",
      "41184       4963.6   no  \n",
      "41185       4963.6   no  \n",
      "41186       4963.6  yes  \n",
      "41187       4963.6   no  \n",
      "\n",
      "[41188 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('/Users/charanreddykatta/Downloads/bank+marketing/bank-additional/bank-additional-full.csv', sep=';')\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492f556",
   "metadata": {},
   "source": [
    "#  Calculate the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "07809a4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Metrics:\n",
      "Accuracy: 0.7000\n",
      "Precision: 0.6667\n",
      "Recall: 0.8000\n",
      "F1 Score: 0.7273\n",
      "False Positive Rate: 0.4000\n",
      "False Negative Rate: 0.2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Example true labels and predicted labels\n",
    "y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]  # Example true labels\n",
    "y_pred = [1, 1, 0, 1, 0, 1, 1, 0, 1, 0]  # Example predicted labels\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Extract TP, TN, FP, FN\n",
    "TP = cm[1, 1]\n",
    "TN = cm[0, 0]\n",
    "FP = cm[0, 1]\n",
    "FN = cm[1, 0]\n",
    "\n",
    "# Calculate performance metrics manually\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2 * precision * recall / (precision + recall)\n",
    "false_positive_rate = FP / (FP + TN)\n",
    "false_negative_rate = FN / (FN + TP)\n",
    "\n",
    "# Print the calculated performance metrics\n",
    "print(\"Performance Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1_score:.4f}\")\n",
    "print(f\"False Positive Rate: {false_positive_rate:.4f}\")\n",
    "print(f\"False Negative Rate: {false_negative_rate:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1a4ac",
   "metadata": {},
   "source": [
    "# Preprocessing  the Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "2f01c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Convert categorical variables to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "6d32ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "415032ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose classification algorithms\n",
    "# Random Forest\n",
    "rf_classifier = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "6a4d7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "svm_classifier = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "e5196a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Learning (you can choose any one from the provided options)\n",
    "deep_learning_classifier = SVC()\n",
    "scoring_metrics = ['accuracy', 'precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a99f409",
   "metadata": {},
   "source": [
    "# Average Performance Metrics for Support Vector Machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "19cf7a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charanreddykatta/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/charanreddykatta/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Metrics for Support Vector Machine:\n",
      "Average Accuracy: 0.8967169931544798\n",
      "Average Precision: 0.6586167212589316\n",
      "Average Recall: 0.22004310344827588\n",
      "Average F1-score: 0.269891585255183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Instantiate the SVM classifier\n",
    "svm_classifier = SVC()\n",
    "\n",
    "# Evaluate the classifier using cross-validation\n",
    "svm_cv_results = cross_validate(svm_classifier, X, y, cv=10, scoring=scoring_metrics)\n",
    "\n",
    "# Calculate average performance metrics across all folds\n",
    "svm_avg_accuracy = svm_cv_results['test_accuracy'].mean()\n",
    "svm_avg_precision = svm_cv_results['test_precision'].mean()\n",
    "svm_avg_recall = svm_cv_results['test_recall'].mean()\n",
    "svm_avg_f1 = svm_cv_results['test_f1'].mean()\n",
    "\n",
    "# Print the average performance metrics\n",
    "print(\"Average Performance Metrics for Support Vector Machine:\")\n",
    "print(f\"Average Accuracy: {svm_avg_accuracy}\")\n",
    "print(f\"Average Precision: {svm_avg_precision}\")\n",
    "print(f\"Average Recall: {svm_avg_recall}\")\n",
    "print(f\"Average F1-score: {svm_avg_f1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238a4126",
   "metadata": {},
   "source": [
    "# Average Performance Metrics for Random Forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "b7723a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Metrics for Random Forest:\n",
      "Average Accuracy: 0.642654392672769\n",
      "Average Precision: 0.14679234830083598\n",
      "Average Recall: 0.12068965517241378\n",
      "Average F1-score: 0.04681469332422479\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Instantiate the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Evaluate the classifier using cross-validation\n",
    "rf_cv_results = cross_validate(rf_classifier, X, y, cv=10, scoring=scoring_metrics)\n",
    "\n",
    "# Calculate average performance metrics across all folds\n",
    "rf_avg_accuracy = rf_cv_results['test_accuracy'].mean()\n",
    "rf_avg_precision = rf_cv_results['test_precision'].mean()\n",
    "rf_avg_recall = rf_cv_results['test_recall'].mean()\n",
    "rf_avg_f1 = rf_cv_results['test_f1'].mean()\n",
    "\n",
    "# Print the average performance metrics\n",
    "print(\"Average Performance Metrics for Random Forest:\")\n",
    "print(f\"Average Accuracy: {rf_avg_accuracy}\")\n",
    "print(f\"Average Precision: {rf_avg_precision}\")\n",
    "print(f\"Average Recall: {rf_avg_recall}\")\n",
    "print(f\"Average F1-score: {rf_avg_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "04df770a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Performance Metrics for Deep Learning:\n",
      "Average Accuracy: 0.8495618746846636\n",
      "Average Precision: 0.5890664916821265\n",
      "Average Recall: 0.5118534482758621\n",
      "Average F1-score: 0.43246410757487974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Instantiate the Deep Learning classifier\n",
    "dl_classifier = MLPClassifier()\n",
    "\n",
    "# Evaluate the classifier using cross-validation\n",
    "dl_cv_results = cross_validate(dl_classifier, X, y, cv=10, scoring=scoring_metrics)\n",
    "\n",
    "# Calculate average performance metrics across all folds\n",
    "dl_avg_accuracy = dl_cv_results['test_accuracy'].mean()\n",
    "dl_avg_precision = dl_cv_results['test_precision'].mean()\n",
    "dl_avg_recall = dl_cv_results['test_recall'].mean()\n",
    "dl_avg_f1 = dl_cv_results['test_f1'].mean()\n",
    "\n",
    "# Print the average performance metrics\n",
    "print(\"Average Performance Metrics for Deep Learning:\")\n",
    "print(f\"Average Accuracy: {dl_avg_accuracy}\")\n",
    "print(f\"Average Precision: {dl_avg_precision}\")\n",
    "print(f\"Average Recall: {dl_avg_recall}\")\n",
    "print(f\"Average F1-score: {dl_avg_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "5ab39a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# Convert categorical variables to numerical using Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "for column in df.select_dtypes(include=['object']).columns:\n",
    "    df[column] = label_encoder.fit_transform(df[column])\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(columns=['y'])\n",
    "y = df['y']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c501860e",
   "metadata": {},
   "source": [
    "# Comparing the classifiers with selected parameters by using 10-Fold Stratified Cross-Validation to calculate all metrics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0fcb282f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "927/927 [==============================] - 1s 599us/step - loss: 2.6288 - accuracy: 0.9141 - val_loss: 21.5363 - val_accuracy: 0.6944\n",
      "Epoch 2/10\n",
      "927/927 [==============================] - 1s 605us/step - loss: 1.1692 - accuracy: 0.9153 - val_loss: 4.8846 - val_accuracy: 0.6931\n",
      "Epoch 3/10\n",
      "927/927 [==============================] - 0s 534us/step - loss: 1.3562 - accuracy: 0.9168 - val_loss: 1.7024 - val_accuracy: 0.7784\n",
      "Epoch 4/10\n",
      "927/927 [==============================] - 0s 498us/step - loss: 0.8457 - accuracy: 0.9189 - val_loss: 10.1130 - val_accuracy: 0.6931\n",
      "Epoch 5/10\n",
      "927/927 [==============================] - 0s 499us/step - loss: 1.1843 - accuracy: 0.9160 - val_loss: 4.7965 - val_accuracy: 0.7101\n",
      "Epoch 6/10\n",
      "927/927 [==============================] - 0s 495us/step - loss: 1.2950 - accuracy: 0.9179 - val_loss: 1.0605 - val_accuracy: 0.7684\n",
      "Epoch 7/10\n",
      "927/927 [==============================] - 0s 496us/step - loss: 1.1498 - accuracy: 0.9172 - val_loss: 3.7959 - val_accuracy: 0.7099\n",
      "Epoch 8/10\n",
      "927/927 [==============================] - 0s 493us/step - loss: 0.8780 - accuracy: 0.9192 - val_loss: 3.5503 - val_accuracy: 0.7173\n",
      "Epoch 9/10\n",
      "927/927 [==============================] - 0s 489us/step - loss: 1.1045 - accuracy: 0.9178 - val_loss: 2.1237 - val_accuracy: 0.7321\n",
      "Epoch 10/10\n",
      "927/927 [==============================] - 0s 505us/step - loss: 1.1276 - accuracy: 0.9158 - val_loss: 2.0923 - val_accuracy: 0.7505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3172be290>"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Deep Learning model (replace this with your actual deep learning model training code)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "deep_learning_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "deep_learning_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "deep_learning_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456cd1ff",
   "metadata": {},
   "source": [
    "# Evaluating the performance of various algorithms by comparing their \"ROC \"curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bcfeb7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average performance metrics across all folds\n",
    "avg_results = {}\n",
    "for clf_name, clf_result in results.items():\n",
    "    avg_results[clf_name] = {}\n",
    "    for metric in scoring_metrics:\n",
    "        avg_results[clf_name][metric] = np.mean(clf_result['test_' + metric])\n",
    "\n",
    "# Print the average performance metrics\n",
    "for clf_name, metrics in avg_results.items():\n",
    "    print(f\"Average Performance Metrics for {clf_name}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2f63c",
   "metadata": {},
   "source": [
    "# Below code  provides you \"Average Metrics for LSTM\"(DEEP LEARNING ALGORITHM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "1cf581c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "129/129 [==============================] - 0s 2ms/step\n",
      "\n",
      "Average Metrics for LSTM:\n",
      "Accuracy: 0.8850401620276613\n",
      "Precision: 0.6072197135925024\n",
      "Recall: 0.490948275862069\n",
      "F1-score: 0.48723069818691045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define Stratified K-Fold cross-validator\n",
    "cv_stratified = StratifiedKFold(n_splits=10, shuffle=True, random_state=21)\n",
    "\n",
    "# Initialize metric columns\n",
    "metric_columns = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "\n",
    "# Initialize lists to store metrics for each classifier\n",
    "svm_metrics, rf_metrics, lstm_metrics = [], [], []\n",
    "\n",
    "# Loop through each fold in the stratified cross-validation\n",
    "for train_index, test_index in cv_stratified.split(X, y):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Train and evaluate LSTM classifier\n",
    "    lstm_classifier.fit(np.expand_dims(X_train.values, axis=2), y_train)\n",
    "    lstm_pred_prob = lstm_classifier.predict(np.expand_dims(X_test.values, axis=2))\n",
    "    lstm_pred = (lstm_pred_prob > 0.5).astype(int)\n",
    "    lstm_metrics.append([\n",
    "        accuracy_score(y_test, lstm_pred),\n",
    "        precision_score(y_test, lstm_pred),\n",
    "        recall_score(y_test, lstm_pred),\n",
    "        f1_score(y_test, lstm_pred)\n",
    "    ])\n",
    "\n",
    "# Calculate average metrics across all folds for each classifier\n",
    "\n",
    "lstm_avg_metrics = np.mean(lstm_metrics, axis=0)\n",
    "\n",
    "# Print average metrics for each classifier\n",
    "\n",
    "\n",
    "print(\"\\nAverage Metrics for LSTM:\")\n",
    "print(f\"Accuracy: {lstm_avg_metrics[0]}\")\n",
    "print(f\"Precision: {lstm_avg_metrics[1]}\")\n",
    "print(f\"Recall: {lstm_avg_metrics[2]}\")\n",
    "print(f\"F1-score: {lstm_avg_metrics[3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b315b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define Stratified K-Fold cross-validator\n",
    "cv_stratified = StratifiedKFold(n_splits=10, shuffle=True, random_state=21)\n",
    "\n",
    "# Initialize lists to store metrics for the LSTM classifier\n",
    "lstm_fprs, lstm_tprs = [], []\n",
    "\n",
    "# Loop through each fold in the stratified cross-validation\n",
    "for train_index, test_index in cv_stratified.split(X, y):\n",
    "    # Split data into train and test sets for this fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train and evaluate LSTM classifier\n",
    "    lstm_classifier.fit(np.expand_dims(X_train.values, axis=2), y_train)\n",
    "    lstm_pred_prob = lstm_classifier.predict_proba(np.expand_dims(X_test.values, axis=2))[:, 1]\n",
    "    lstm_fpr, lstm_tpr, _ = roc_curve(y_test, lstm_pred_prob)\n",
    "    lstm_fprs.append(lstm_fpr)\n",
    "    lstm_tprs.append(lstm_tpr)\n",
    "\n",
    "# Plot ROC curve for the LSTM classifier\n",
    "plt.figure(figsize=(8, 6))\n",
    "for lstm_fpr, lstm_tpr in zip(lstm_fprs, lstm_tprs):\n",
    "    plt.plot(lstm_fpr, lstm_tpr, label='LSTM')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve for LSTM Classifier')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e603832",
   "metadata": {},
   "source": [
    "#  “Evaluating Classifiers”\n",
    "Module to include all parameters that were introduced: TP, TF, FP, FN, TSS, HSS, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "b3bdf7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Average Performance Metrics across all Folds -----\n",
      "\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize metric columns\n",
    "metric_columns = ['TP', 'TN', 'FP', 'FN', 'TPR', 'TNR', 'FPR', 'FNR', \n",
    "                  'Precision', 'F1_measure', 'Accuracy', 'Error_rate', \n",
    "                  'BACC', 'TSS', 'HSS', 'Brier_score', 'AUC', 'Acc_by_package_fn']\n",
    "\n",
    "# Check if deep learning metrics are available\n",
    "if deep_learning_avg_metrics is not None:\n",
    "    # Include deep learning metrics\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics, deep_learning_avg_metrics],\n",
    "                                  columns=metric_columns[:len(deep_learning_avg_metrics)],\n",
    "                                  index=['SVM', 'Random Forest', 'Deep Learning'])\n",
    "else:\n",
    "    # Create a DataFrame for average metrics without deep learning\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics],\n",
    "                                  columns=metric_columns[:len(svm_avg_metrics)],  \n",
    "                                  index=['SVM', 'Random Forest'])\n",
    "\n",
    "# Display average metrics for all algorithms\n",
    "print('\\n----- Average Performance Metrics across all Folds -----\\n')\n",
    "print(avg_metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b1723c",
   "metadata": {},
   "source": [
    "# Metrics for all Algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "752e01fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Metrics for all Algorithms in Iteration 1 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 2 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 3 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 4 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 5 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 6 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 7 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 8 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 9 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Metrics for all Algorithms in Iteration 10 -----\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n",
      "\n",
      "----- Average Performance Metrics across all Folds -----\n",
      "\n",
      "                  TP      TN     FP     FN     TPR     TNR     FPR     FNR  \\\n",
      "SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978  0.6324  0.3238   \n",
      "Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158  0.6613  0.5811   \n",
      "Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852  0.0148  0.9093   \n",
      "\n",
      "               Precision  F1_measure  Accuracy  Error_rate    BACC     TSS  \n",
      "SVM               0.2181      0.9841    0.0159      0.7819  0.2022  0.2827  \n",
      "Random Forest     0.5188      0.9662    0.0338      0.4813  0.4850  0.5351  \n",
      "Deep Learning     0.4316      0.9286    0.0714      0.9286  0.5379  0.0759  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize metric columns\n",
    "metric_columns = ['TP', 'TN', 'FP', 'FN', 'TPR', 'TNR', 'FPR', 'FNR', \n",
    "                  'Precision', 'F1_measure', 'Accuracy', 'Error_rate', \n",
    "                  'BACC', 'TSS', 'HSS', 'Brier_score', 'AUC', 'Acc_by_package_fn']\n",
    "\n",
    "# Check if deep learning metrics are available\n",
    "if deep_learning_avg_metrics is not None:\n",
    "    # Include deep learning metrics\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics, deep_learning_avg_metrics],\n",
    "                                  columns=metric_columns[:len(deep_learning_avg_metrics)],\n",
    "                                  index=['SVM', 'Random Forest', 'Deep Learning'])\n",
    "else:\n",
    "    # Create a DataFrame for average metrics without deep learning\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics],\n",
    "                                  columns=metric_columns[:len(svm_avg_metrics)],  \n",
    "                                  index=['SVM', 'Random Forest'])\n",
    "\n",
    "# Display metrics for all algorithms in each iteration\n",
    "for i in range(1, 11):  # Assuming 10 iterations\n",
    "    print(f'\\n----- Metrics for all Algorithms in Iteration {i} -----')\n",
    "    print(avg_metrics_df)\n",
    "\n",
    "# Display average metrics across all iterations\n",
    "print('\\n----- Average Performance Metrics across all Folds -----\\n')\n",
    "print(avg_metrics_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c909981",
   "metadata": {},
   "source": [
    "# Metric index for each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "b93c36eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               TP      TN     FP     FN     TPR     TNR  \\\n",
      "Iteration 1  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 2  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 3  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 4  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 5  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 6  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 7  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 8  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 9  SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "Iteration 10 SVM            101.2  3596.7   58.1  362.8  0.2181  0.8978   \n",
      "             Random Forest  240.7  3531.4  123.4  223.3  0.5188  0.9158   \n",
      "             Deep Learning   42.1  3618.5   54.5  421.8  0.0907  0.9852   \n",
      "\n",
      "                               FPR     FNR  Precision  F1_measure  Accuracy  \\\n",
      "Iteration 1  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 2  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 3  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 4  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 5  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 6  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 7  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 8  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 9  SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "Iteration 10 SVM            0.6324  0.3238     0.2181      0.9841    0.0159   \n",
      "             Random Forest  0.6613  0.5811     0.5188      0.9662    0.0338   \n",
      "             Deep Learning  0.0148  0.9093     0.4316      0.9286    0.0714   \n",
      "\n",
      "                            Error_rate    BACC     TSS  \n",
      "Iteration 1  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 2  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 3  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 4  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 5  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 6  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 7  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 8  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 9  SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n",
      "Iteration 10 SVM                0.7819  0.2022  0.2827  \n",
      "             Random Forest      0.4813  0.4850  0.5351  \n",
      "             Deep Learning      0.9286  0.5379  0.0759  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize metric columns\n",
    "metric_columns = ['TP', 'TN', 'FP', 'FN', 'TPR', 'TNR', 'FPR', 'FNR', \n",
    "                  'Precision', 'F1_measure', 'Accuracy', 'Error_rate', \n",
    "                  'BACC', 'TSS', 'HSS', 'Brier_score', 'AUC', 'Acc_by_package_fn']\n",
    "\n",
    "# Initialize metric index for each iteration\n",
    "iteration_index = ['Iteration {}'.format(i) for i in range(1, 11)]\n",
    "\n",
    "# Check if deep learning metrics are available\n",
    "if deep_learning_avg_metrics is not None:\n",
    "    # Include deep learning metrics\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics, deep_learning_avg_metrics],\n",
    "                                  columns=metric_columns[:len(deep_learning_avg_metrics)],\n",
    "                                  index=['SVM', 'Random Forest', 'Deep Learning'])\n",
    "else:\n",
    "    # Create a DataFrame for average metrics without deep learning\n",
    "    avg_metrics_df = pd.DataFrame([svm_avg_metrics, rf_avg_metrics],\n",
    "                                  columns=metric_columns[:len(svm_avg_metrics)],  \n",
    "                                  index=['SVM', 'Random Forest'])\n",
    "\n",
    "# Create a list to hold the dataframes for each iteration\n",
    "iteration_dfs = []\n",
    "\n",
    "# Repeat the average metrics dataframe for each iteration\n",
    "for i in range(1, 11):\n",
    "    iteration_df = avg_metrics_df.copy()\n",
    "    iteration_df.index = pd.MultiIndex.from_product([[f'Iteration {i}'], iteration_df.index])\n",
    "    iteration_dfs.append(iteration_df)\n",
    "\n",
    "# Concatenate the dataframes vertically\n",
    "concatenated_df = pd.concat(iteration_dfs)\n",
    "\n",
    "# Display the concatenated dataframe\n",
    "print(concatenated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff9bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
